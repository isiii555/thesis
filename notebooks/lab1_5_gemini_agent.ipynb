{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvG6idnMI0oIKeTJUNMMyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isiii555/thesis/blob/main/notebooks/lab1_5_gemini_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLW7n7aEnaOW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî• End-to-End AI System Demonstration using Gemini API  \n",
        "## Master Thesis ‚Äî Software System Event Log Analysis using AI-Driven Process Mining\n",
        "\n",
        "This Colab notebook demonstrates the end-to-end functioning of the thesis-based AI system using **Gemini API**.  \n",
        "The AI agent receives **raw heterogeneous software logs (X)** and processes them through the full pipeline:\n",
        "\n",
        "1) Log preprocessing  \n",
        "2) Smart trace construction  \n",
        "3) XES event log export  \n",
        "4) Process discovery with **Inductive Miner & Heuristic Miner**  \n",
        "5) Model evaluation (fitness, precision, generalization, simplicity)  \n",
        "6) Diagnostic insights generation\n",
        "\n",
        "This notebook extends **Lab 1.4 (Prompt Engineering)** by running the previously designed prompts through **Gemini API in a real environment**.\n"
      ],
      "metadata": {
        "id": "aB4rfBCOnh5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "fo2ySlkFnlPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEMINI_KEY = userdata.get('GEMINI_KEY')\n",
        "assert GEMINI_KEY is not None, \"‚ùå ERROR: GEMINI_KEY secret not found. Go to Tools ‚Üí Secrets and create it.\"\n",
        "genai.configure(api_key=GEMINI_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "print(\"‚úÖ Gemini API initialized successfully\")\n"
      ],
      "metadata": {
        "id": "5N8LxbObnqXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1_url = \"https://raw.githubusercontent.com/isiii555/thesis/main/data/lab4/prompts/prompt1_zero_shot.md\"\n",
        "prompt2_url = \"https://raw.githubusercontent.com/isiii555/thesis/main/data/lab4/prompts/prompt2_few_shot.md\"\n",
        "\n",
        "prompt1 = requests.get(prompt1_url).text\n",
        "prompt2 = requests.get(prompt2_url).text\n",
        "\n",
        "print(\"üìå Prompts loaded successfully\")\n"
      ],
      "metadata": {
        "id": "nsytTsBnock5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîé Running Zero-shot prompt...\")\n",
        "response1 = model.generate_content(prompt1)\n",
        "print(\"\\n===== üí° Zero-shot Output y =====\\n\")\n",
        "print(response1.text)\n"
      ],
      "metadata": {
        "id": "ZTDkVeTBoi3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîé Running Few-shot prompt...\")\n",
        "response2 = model.generate_content(prompt2)\n",
        "print(\"\\n===== üí° Few-shot Output y =====\\n\")\n",
        "print(response2.text)\n"
      ],
      "metadata": {
        "id": "g66FLz7yok98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_logs = \"\"\"\n",
        "[2024-12-01 11:21:03] INFO GET /order?id=552\n",
        "[2024-12-01 11:21:04] INFO DB lookup id=552\n",
        "[2024-12-01 11:21:06] WARN Payment API delay 650ms id=552\n",
        "[2024-12-01 11:21:10] INFO Order confirmation rendered id=552\n",
        "\"\"\"\n",
        "\n",
        "dynamic_prompt = f\"\"\"\n",
        "You are an AI Agent for Software System Log Analysis and Process Mining.\n",
        "You must process the following raw logs end-to-end and produce output y:\n",
        "\n",
        "{new_logs}\n",
        "\n",
        "Return output strictly in JSON with:\n",
        "constructed_trace, xes_summary, process_model_description,\n",
        "model_evaluation (fitness, precision, generalization, simplicity),\n",
        "diagnostic_insights.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üöÄ Running fully dynamic end-to-end evaluation...\")\n",
        "response3 = model.generate_content(dynamic_prompt)\n",
        "print(\"\\n===== üí° End-to-End Output y =====\\n\")\n",
        "print(response3.text)\n"
      ],
      "metadata": {
        "id": "23y0JJduomuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Reflection\n",
        "\n",
        "This laboratory work demonstrated my thesis system as a fully functional end-to-end AI agent using the Gemini API.  \n",
        "By integrating prompt engineering inside Google Colab, the agent was able to accept raw system logs, infer behavior, construct event traces, discover process models, evaluate them using standard metrics, and generate actionable diagnostic insights. The zero-shot and few-shot examples showed that prompt patterns significantly influence the agent‚Äôs reasoning quality. Using the Gemini API provided a realistic environment to simulate the behavior of an intelligent log-analysis assistant.  \n",
        "What worked well was the clear structure of the prompts and the abstraction of the pipeline into a single AI agent. A limitation was that results depend on the LLM‚Äôs internal knowledge rather than deterministic computation. In the future, hybrid integration with real event log miners (e.g., PM4Py) could improve trace accuracy and reproducibility.\n"
      ],
      "metadata": {
        "id": "8MnP7KXhor0k"
      }
    }
  ]
}